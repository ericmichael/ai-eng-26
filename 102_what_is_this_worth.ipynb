{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agents Can See\n",
    "\n",
    "A common misconception: LLMs only work with text.\n",
    "\n",
    "Modern LLMs are **multimodal** ‚Äî they can see images, possibly even hear audio, and reason about what they perceive.\n",
    "\n",
    "This changes everything for agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osyja0zb9iq",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perception + Action\n",
    "\n",
    "With vision, agents can:\n",
    "\n",
    "- **Perceive the user's world** ‚Äî analyze photos, documents, screenshots\n",
    "- **Perceive their own environment** ‚Äî see a computer screen, a video game, a robot's camera\n",
    "\n",
    "Give an agent eyes and hands, and it can interact with the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owzx34yafo",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Is This Worth?\n",
    "\n",
    "Let's build an agent that can take advantage of its ability to see and help us with useful real-world stuff.\n",
    "\n",
    "1. **See** ‚Äî Analyze an image\n",
    "2. **Research** ‚Äî Search the web for additional information\n",
    "3. **Synthesize** ‚Äî Return insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8aa489-2e74-4f40-8af1-9a6aaebcf5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(Path.cwd() / \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner as AgentRunner\n",
    "from omniagents import Runner, function_tool\n",
    "from omniagents.builtin.tools import web_search, web_fetch, read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-intro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Tools\n",
    "\n",
    "| Tool | Purpose |\n",
    "|------|--------|\n",
    "| `read_image` | Analyze images (photos, screenshots, documents) |\n",
    "| `web_search` | Search the web for current information |\n",
    "| `web_fetch` | Fetch and read content from specific URLs |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-section",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-agent",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"\n",
    "You are an expert appraiser and researcher. When a user asks about an item and\n",
    "provides an image path, you MUST first call read_image with that path to see the image.\n",
    "\n",
    "1. **Identify** - Use read_image to analyze what the item is. Be specific:\n",
    "   - For collectibles: edition, year, manufacturer, condition indicators\n",
    "   - For products: brand, model, distinguishing features\n",
    "   - For clothing: brand, style, materials, designer indicators\n",
    "\n",
    "2. **Research** - Search for current market values:\n",
    "   - Use web_search to find recent sales, price guides, or market data\n",
    "   - Look for multiple sources to triangulate value\n",
    "   - Consider condition, rarity, and market demand\n",
    "\n",
    "3. **Assess** - Provide a valuation with:\n",
    "   - Price range (low to high based on condition)\n",
    "   - Key factors affecting value\n",
    "   - Recommendations (e.g., get it graded, where to sell)\n",
    "\n",
    "Be enthusiastic when you find something valuable! Provide context that helps\n",
    "the user understand *why* something is worth what it is.\n",
    "\"\"\"\n",
    "\n",
    "appraiser = Agent(\n",
    "    name=\"What Is This Worth?\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[read_image, web_search, web_fetch],\n",
    "    model=\"gpt-4.1\",  # Vision-capable model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1-intro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1: What is this worth?\n",
    "\n",
    "![Example 1](examples/1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "runner = Runner.from_agent(appraiser)\n",
    "runner.run_notebook(input=\"What is this worth? examples/1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2-intro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2: What would it cost to fix or replace?\n",
    "\n",
    "![Example 2](examples/2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "runner = Runner.from_agent(appraiser)\n",
    "runner.run_notebook(input=\"What would it cost to fix or replace this? examples/2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example3-intro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3: Where can I find this style?\n",
    "\n",
    "![Example 3](examples/3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "runner = Runner.from_agent(appraiser)\n",
    "runner.run_notebook(input=\"I love this style! Can you identify these outfits and tell me where I could find similar pieces? examples/3.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive-section",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Try It Yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "runner = Runner.from_agent(appraiser)\n",
    "runner.run_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "how-it-works",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How It Works\n",
    "\n",
    "| Step | What Happens |\n",
    "|------|--------------|\n",
    "| 1 | Receive message + image |\n",
    "| 2 | Call `read_image` ‚Üí identify the item |\n",
    "| 3 | Call `web_search` ‚Üí find current prices |\n",
    "| 4 | Synthesize ‚Üí return valuation |\n",
    "\n",
    "The agent chooses what tools to use and in what order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What We Just Did\n",
    "\n",
    "We gave an agent:\n",
    "- **Eyes** ‚Äî `read_image` to perceive\n",
    "- **Research ability** ‚Äî `web_search` to gather information\n",
    "- **Instructions** ‚Äî How to think about valuation\n",
    "\n",
    "The agent figured out the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1v6rv2i5fly",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Else Could an Agent See?\n",
    "\n",
    "If an agent can see images you upload...\n",
    "\n",
    "What if it could see:\n",
    "- üñ•Ô∏è Its own computer screen?\n",
    "- üéÆ A video game it's playing?\n",
    "- ü§ñ A robot's camera feed?\n",
    "- üìπ A live video stream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lp6pepmbvm9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perception ‚Üí Action\n",
    "\n",
    "| Agent Can See | Agent Can Do |\n",
    "|---------------|--------------|\n",
    "| Computer screen | Click, type, navigate |\n",
    "| Video game | Click, type, navigate |\n",
    "| Robot camera | Move, grab, manipulate |\n",
    "| Security feed | Alert, respond, dispatch |\n",
    "\n",
    "**Vision + Tools = Agents that interact with the real world**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "rise": {
   "autolaunch": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
